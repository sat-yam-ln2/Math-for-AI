{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d035cbb8",
   "metadata": {},
   "source": [
    "# ‚ö° Stochastic Gradient Descent (SGD) and its Variants\n",
    "\n",
    "> *\"The great advantage of stochastic gradient descent is its simplicity and effectiveness. It's the workhorse of deep learning.\"*\n",
    "\n",
    "In the previous notebook, we learned about Gradient Descent (GD). A major drawback of this \"vanilla\" GD is that it requires computing the gradient of the loss function over the **entire training dataset** for every single update. For modern datasets with millions of samples, this is incredibly slow and computationally expensive.\n",
    "\n",
    "Enter **Stochastic Gradient Descent (SGD)**, a more efficient and widely used alternative.\n",
    "\n",
    "## üéØ What You'll Master\n",
    "\n",
    "- **Batch vs. Mini-Batch vs. Stochastic GD**: Understanding the different flavors of gradient descent.\n",
    "- **The Power of Noise**: How SGD's noisy updates can help escape local minima.\n",
    "- **Convergence and Trade-offs**: Comparing the optimization paths of different GD variants.\n",
    "- **Momentum**: A simple but powerful technique to accelerate SGD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf976ce2",
   "metadata": {},
   "source": [
    "## üìö Import Essential Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45806f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Create a synthetic dataset for linear regression\n",
    "np.random.seed(42)\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y = 4 + 3 * X + np.random.randn(100, 1)\n",
    "X_b = np.c_[np.ones((100, 1)), X]  # Add x0 = 1 to each instance for the bias term\n",
    "\n",
    "print(\"‚ö° Libraries and synthetic data loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e4d3b2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ‚öñÔ∏è Chapter 1: The Gradient Descent Family\n",
    "\n",
    "The difference between the variants lies in **how much data we use** to compute the gradient at each step.\n",
    "\n",
    "1. **Batch Gradient Descent (GD)**\n",
    "   - **Method**: Uses the **entire** training set for each gradient calculation and parameter update.\n",
    "   - **Pros**: Smooth, direct convergence path.\n",
    "   - **Cons**: Very slow and memory-intensive for large datasets.\n",
    "\n",
    "2. **Stochastic Gradient Descent (SGD)**\n",
    "   - **Method**: Uses **one single, randomly chosen** training instance for each gradient calculation and update.\n",
    "   - **Pros**: Very fast per update, low memory usage.\n",
    "   - **Cons**: Very noisy (stochastic) path. The loss can fluctuate wildly. Never truly 'settles' at the minimum.\n",
    "\n",
    "3. **Mini-Batch Gradient Descent**\n",
    "   - **Method**: A compromise. Uses a **small, random batch** of instances (e.g., 32, 64) for each update.\n",
    "   - **Pros**: The best of both worlds. Faster and more stable than SGD, more efficient than Batch GD. This is the **standard approach** in deep learning.\n",
    "   - **Cons**: Adds another hyperparameter (the batch size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63318740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sgd_paths():\n",
    "    \"\"\"\n",
    "    Implement and visualize the paths of Batch, Stochastic, and Mini-Batch GD.\n",
    "    \"\"\"\n",
    "    n_epochs = 50\n",
    "    t0, t1 = 5, 50  # Learning schedule hyperparameters for SGD/Mini-batch\n",
    "\n",
    "    def learning_schedule(t):\n",
    "        return t0 / (t + t1)\n",
    "\n",
    "    # --- Batch GD ---\n",
    "    theta_batch = np.random.randn(2, 1)\n",
    "    path_batch = [theta_batch]\n",
    "    learning_rate_batch = 0.1\n",
    "    for epoch in range(n_epochs):\n",
    "        gradients = 2/100 * X_b.T.dot(X_b.dot(theta_batch) - y)\n",
    "        theta_batch = theta_batch - learning_rate_batch * gradients\n",
    "        path_batch.append(theta_batch)\n",
    "    path_batch = np.array(path_batch)\n",
    "\n",
    "    # --- Stochastic GD ---\n",
    "    theta_sgd = np.random.randn(2, 1)\n",
    "    path_sgd = [theta_sgd]\n",
    "    for epoch in range(n_epochs):\n",
    "        for i in range(100):\n",
    "            random_index = np.random.randint(100)\n",
    "            xi = X_b[random_index:random_index+1]\n",
    "            yi = y[random_index:random_index+1]\n",
    "            gradients = 2 * xi.T.dot(xi.dot(theta_sgd) - yi)\n",
    "            eta = learning_schedule(epoch * 100 + i)\n",
    "            theta_sgd = theta_sgd - eta * gradients\n",
    "            path_sgd.append(theta_sgd)\n",
    "    path_sgd = np.array(path_sgd)\n",
    "\n",
    "    # --- Mini-Batch GD ---\n",
    "    theta_mini = np.random.randn(2, 1)\n",
    "    path_mini = [theta_mini]\n",
    "    batch_size = 20\n",
    "    for epoch in range(n_epochs):\n",
    "        shuffled_indices = np.random.permutation(100)\n",
    "        X_b_shuffled = X_b[shuffled_indices]\n",
    "        y_shuffled = y[shuffled_indices]\n",
    "        for i in range(0, 100, batch_size):\n",
    "            xi = X_b_shuffled[i:i+batch_size]\n",
    "            yi = y_shuffled[i:i+batch_size]\n",
    "            gradients = 2/batch_size * xi.T.dot(xi.dot(theta_mini) - yi)\n",
    "            eta = learning_schedule(epoch * (100/batch_size) + i/batch_size)\n",
    "            theta_mini = theta_mini - eta * gradients\n",
    "            path_mini.append(theta_mini)\n",
    "    path_mini = np.array(path_mini)\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(path_batch[:, 0], path_batch[:, 1], \"b-o\", linewidth=3, label=\"Batch GD\")\n",
    "    plt.plot(path_sgd[:, 0], path_sgd[:, 1], \"r-s\", linewidth=1, label=\"Stochastic GD\", markersize=1, alpha=0.6)\n",
    "    plt.plot(path_mini[:, 0], path_mini[:, 1], \"g-^\", linewidth=2, label=\"Mini-Batch GD\", markersize=3)\n",
    "    \n",
    "    # True parameters\n",
    "    true_theta = np.array([[4], [3]])\n",
    "    plt.plot(true_theta[0], true_theta[1], 'y*', markersize=20, label='True Minimum')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.xlabel(r\"$\\theta_0$ (Bias)\")\n",
    "    plt.ylabel(r\"$\\theta_1$ (Weight)\")\n",
    "    plt.title(\"Comparison of Gradient Descent Optimization Paths\", fontsize=16, weight='bold')\n",
    "    plt.axis([2.5, 4.5, 2, 4])\n",
    "    plt.show()\n",
    "\n",
    "plot_sgd_paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bc179a",
   "metadata": {},
   "source": [
    "### Analysis of the Paths\n",
    "\n",
    "- **Batch GD (Blue)**: Takes a smooth, direct path straight to the minimum. It's predictable but slow.\n",
    "- **Stochastic GD (Red)**: Bounces around erratically. It gets to the vicinity of the minimum quickly but then continues to dance around it, never fully settling. The individual steps are very fast.\n",
    "- **Mini-Batch GD (Green)**: A happy medium. It's less erratic than SGD but arrives at the minimum much faster than Batch GD. This is the clear winner for most applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ccbf0b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üé¢ Chapter 2: The Power of Momentum\n",
    "\n",
    "A problem with standard SGD is that it can be slow when navigating long, flat valleys in the loss surface. It will tend to oscillate back and forth across the narrow axis while making slow progress along the main axis.\n",
    "\n",
    "**Momentum** is a technique that helps accelerate SGD in the relevant direction and dampens oscillations. It adds a 'memory' of the previous gradient to the current update.\n",
    "\n",
    "### The Momentum Update Rule\n",
    "\n",
    "1. **Update the velocity vector `v`**: \n",
    "   $$ v_{new} = \\beta v_{old} + \\eta \\nabla L(\\theta) $$\n",
    "\n",
    "2. **Update the parameters `Œ∏`**:\n",
    "   $$ \\theta_{new} = \\theta_{old} - v_{new} $$\n",
    "\n",
    "Where:\n",
    "- **`Œ≤` (beta)** is the momentum term (e.g., 0.9). It controls how much of the past velocity is carried over.\n",
    "- The velocity `v` acts like a rolling average of the gradients.\n",
    "\n",
    "**Intuition**: Imagine a ball rolling down a hill. It accumulates momentum, moving faster in the downhill direction and smoothing out its path over small bumps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b11c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_convex_loss(w, b):\n",
    "    \"\"\" A function with a long, narrow valley. \"\"\"\n",
    "    return 0.1 * w**2 + 5 * b**2\n",
    "\n",
    "def non_convex_gradient(w, b):\n",
    "    \"\"\" Gradient for the valley function. \"\"\"\n",
    "    return 0.2 * w, 10 * b\n",
    "\n",
    "def compare_momentum():\n",
    "    \"\"\"\n",
    "    Compare SGD with and without momentum on a challenging loss surface.\n",
    "    \"\"\"\n",
    "    # Parameters\n",
    "    learning_rate = 0.1\n",
    "    n_steps = 40\n",
    "    start_w, start_b = -9, 1.5\n",
    "    \n",
    "    # --- SGD without Momentum ---\n",
    "    path_sgd = [(start_w, start_b)]\n",
    "    w, b = start_w, start_b\n",
    "    for _ in range(n_steps):\n",
    "        grad_w, grad_b = non_convex_gradient(w, b)\n",
    "        w -= learning_rate * grad_w\n",
    "        b -= learning_rate * grad_b\n",
    "        path_sgd.append((w, b))\n",
    "    path_sgd = np.array(path_sgd)\n",
    "\n",
    "    # --- SGD with Momentum ---\n",
    "    path_momentum = [(start_w, start_b)]\n",
    "    w, b = start_w, start_b\n",
    "    beta = 0.9\n",
    "    v_w, v_b = 0, 0\n",
    "    for _ in range(n_steps):\n",
    "        grad_w, grad_b = non_convex_gradient(w, b)\n",
    "        v_w = beta * v_w + learning_rate * grad_w\n",
    "        v_b = beta * v_b + learning_rate * grad_b\n",
    "        w -= v_w\n",
    "        b -= v_b\n",
    "        path_momentum.append((w, b))\n",
    "    path_momentum = np.array(path_momentum)\n",
    "    \n",
    "    # Plotting\n",
    "    w_grid = np.linspace(-10, 10, 100)\n",
    "    b_grid = np.linspace(-2, 2, 100)\n",
    "    W, B = np.meshgrid(w_grid, b_grid)\n",
    "    L = non_convex_loss(W, B)\n",
    "    \n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.contour(W, B, L, levels=20, cmap='viridis')\n",
    "    plt.plot(path_sgd[:, 0], path_sgd[:, 1], 'r-o', label='SGD without Momentum')\n",
    "    plt.plot(path_momentum[:, 0], path_momentum[:, 1], 'b-o', label='SGD with Momentum (Œ≤=0.9)')\n",
    "    plt.plot(0, 0, 'y*', markersize=20, label='Minimum')\n",
    "    plt.legend()\n",
    "    plt.title('The Effect of Momentum', fontsize=16, weight='bold')\n",
    "    plt.xlabel('Parameter w')\n",
    "    plt.ylabel('Parameter b')\n",
    "    plt.show()\n",
    "\n",
    "compare_momentum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7478e5f",
   "metadata": {},
   "source": [
    "### Analysis of Momentum\n",
    "\n",
    "- **SGD without Momentum (Red)**: Oscillates wildly back and forth across the narrow valley (the `b` direction). The steps in the main downhill direction (`w`) are small, so it makes very slow progress.\n",
    "- **SGD with Momentum (Blue)**: The momentum term averages out the oscillations in the `b` direction (the up-and-down gradients cancel each other out). It builds up speed in the consistent `w` direction, allowing it to barrel down the valley much more quickly and directly.\n",
    "\n",
    "This is why optimizers with momentum (and more advanced techniques like Adam) are the default choice in modern deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b14516f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üéØ Key Takeaways\n",
    "\n",
    "## üë™ The Gradient Descent Family\n",
    "- **Batch GD**: Accurate but slow. Uses all data.\n",
    "- **Stochastic GD (SGD)**: Fast but noisy. Uses one data point.\n",
    "- **Mini-Batch GD**: The practical choice. Uses a small batch of data, balancing speed and stability.\n",
    "\n",
    "## üé≤ The Benefit of Noise\n",
    "- The randomness of SGD and Mini-Batch GD can be a feature, not a bug.\n",
    "- The noisy updates can help the algorithm **jump out of poor local minima** and find a better overall solution, which is especially important for the complex, non-convex loss surfaces in deep learning.\n",
    "\n",
    "## üé¢ Accelerating with Momentum\n",
    "- **Momentum** helps SGD to converge faster, especially on surfaces with long, narrow valleys.\n",
    "- It acts as a rolling average of gradients, damping oscillations and accelerating in the consistent downhill direction.\n",
    "\n",
    "---\n",
    "\n",
    "# üöÄ What's Next?\n",
    "\n",
    "While Momentum is a great improvement, the world of optimization has evolved even further. The next notebook will introduce **Adaptive Optimizers** like AdaGrad, RMSprop, and the king of them all, **Adam**.\n",
    "\n",
    "- **Adaptive Learning Rates**: How can we give each parameter its own learning rate?\n",
    "- **RMSprop and AdaGrad**: The building blocks of modern optimizers.\n",
    "- **Adam**: The combination of Momentum and adaptive learning rates that has become the default optimizer for most deep learning tasks.\n",
    "\n",
    "**Ready to adapt? Let's explore the state-of-the-art in optimization! ü§ñ**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
