{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b1bbbe2",
   "metadata": {},
   "source": [
    "# üìâ Gradient Descent: The Engine of Learning\n",
    "\n",
    "> *\"Optimization is the process of finding the best solution from a set of available alternatives.\"*\n",
    "\n",
    "Welcome to **Optimization**! This is the mathematical engine that powers machine learning. It's the process by which a model 'learns' from data by systematically minimizing a **loss function**. In this notebook, we'll explore the most fundamental optimization algorithm: **Gradient Descent**.\n",
    "\n",
    "## üéØ What You'll Master\n",
    "\n",
    "- **Loss Functions**: Understanding how we measure a model's error.\n",
    "- **The Concept of Gradient Descent**: Intuitively understanding how to find the minimum of a function.\n",
    "- **The Learning Rate**: The most important hyperparameter in optimization and its effect on convergence.\n",
    "- **Visualizing Optimization**: Watching the algorithm navigate a loss surface to find the best parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb747c4",
   "metadata": {},
   "source": [
    "## üìö Import Essential Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e0030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Interactive widgets\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "# Plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"üìâ Libraries loaded for our optimization journey!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa578e9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üìâ Chapter 1: The Loss Function\n",
    "\n",
    "Before we can optimize, we need something to optimize! In machine learning, this is the **loss function** (or cost function). It's a function that measures how 'wrong' our model's predictions are compared to the actual data.\n",
    "\n",
    "**The Goal of Optimization**: Find the model parameters (weights and biases) that minimize the value of the loss function.\n",
    "\n",
    "Let's visualize a simple loss surface for a model with two parameters, `w` and `b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bfe5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(w, b):\n",
    "    \"\"\"\n",
    "    A simple quadratic loss function to simulate a model's error surface.\n",
    "    This is a convex function, meaning it has a single global minimum.\n",
    "    \"\"\"\n",
    "    # A simple bowl-shaped function\n",
    "    return (w - 2)**2 + 2 * (b - 3)**2 + 1\n",
    "\n",
    "def visualize_loss_surface():\n",
    "    \"\"\"\n",
    "    Plot the 3D surface and 2D contour of the loss function.\n",
    "    \"\"\"\n",
    "    # Create a grid of w and b values\n",
    "    w = np.linspace(-2, 6, 100)\n",
    "    b = np.linspace(-1, 7, 100)\n",
    "    W, B = np.meshgrid(w, b)\n",
    "    L = loss_function(W, B)\n",
    "    \n",
    "    fig = plt.figure(figsize=(18, 8))\n",
    "    \n",
    "    # 3D surface plot\n",
    "    ax1 = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "    ax1.plot_surface(W, B, L, cmap='viridis', alpha=0.8)\n",
    "    ax1.set_title('3D Loss Surface', fontsize=16, weight='bold')\n",
    "    ax1.set_xlabel('Parameter w')\n",
    "    ax1.set_ylabel('Parameter b')\n",
    "    ax1.set_zlabel('Loss')\n",
    "    \n",
    "    # Mark the minimum\n",
    "    min_w, min_b = 2, 3\n",
    "    min_loss = loss_function(min_w, min_b)\n",
    "    ax1.scatter(min_w, min_b, min_loss, color='red', s=100, label='Global Minimum')\n",
    "    \n",
    "    # 2D contour plot\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    contour = ax2.contour(W, B, L, levels=20, cmap='viridis')\n",
    "    ax2.clabel(contour, inline=True, fontsize=8)\n",
    "    ax2.set_title('Contour Plot of Loss Surface', fontsize=16, weight='bold')\n",
    "    ax2.set_xlabel('Parameter w')\n",
    "    ax2.set_ylabel('Parameter b')\n",
    "    ax2.scatter(min_w, min_b, color='red', s=100, label='Global Minimum')\n",
    "    ax2.legend()\n",
    "    ax2.set_aspect('equal')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"The minimum loss of {min_loss} occurs at (w, b) = ({min_w}, {min_b}).\")\n",
    "    print(\"Our goal is to find this point automatically.\")\n",
    "\n",
    "visualize_loss_surface()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f538b92",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ‚õ∞Ô∏è Chapter 2: The Gradient Descent Algorithm\n",
    "\n",
    "How do we navigate this loss surface to find the minimum? Imagine you are standing on a mountain in a thick fog and want to get to the lowest point. What would you do? You would feel the ground around you and take a step in the steepest downhill direction.\n",
    "\n",
    "This is exactly what Gradient Descent does!\n",
    "\n",
    "1. **Calculate the Gradient**: The gradient (`‚àáL`) is a vector of partial derivatives (`‚àÇL/‚àÇw`, `‚àÇL/‚àÇb`). It points in the direction of the **steepest ascent**.\n",
    "2. **Move in the Opposite Direction**: To go downhill, we take a step in the direction *opposite* to the gradient.\n",
    "3. **Update the Parameters**: We update our parameters (`w` and `b`) based on this step.\n",
    "4. **Repeat**: We repeat this process until we converge to a minimum.\n",
    "\n",
    "### The Update Rule\n",
    "\n",
    "The core of Gradient Descent is the update rule:\n",
    "\n",
    "$$ w_{new} = w_{old} - \\eta \\frac{\\partial L}{\\partial w} $$\n",
    "$$ b_{new} = b_{old} - \\eta \\frac{\\partial L}{\\partial b} $$\n",
    "\n",
    "Where:\n",
    "- **`Œ∑` (eta)** is the **learning rate**, a small positive number that controls the size of our steps.\n",
    "- `‚àÇL/‚àÇw` and `‚àÇL/‚àÇb` are the partial derivatives (the components of the gradient)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4230894c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(w, b):\n",
    "    \"\"\"\n",
    "    Calculates the gradient of the loss function L(w, b) = (w - 2)**2 + 2 * (b - 3)**2 + 1\n",
    "    ‚àÇL/‚àÇw = 2 * (w - 2)\n",
    "    ‚àÇL/‚àÇb = 4 * (b - 3)\n",
    "    \"\"\"\n",
    "    grad_w = 2 * (w - 2)\n",
    "    grad_b = 4 * (b - 3)\n",
    "    return grad_w, grad_b\n",
    "\n",
    "def gradient_descent(start_w, start_b, learning_rate, num_steps):\n",
    "    \"\"\"\n",
    "    Performs the gradient descent optimization.\n",
    "    \"\"\"\n",
    "    path = [(start_w, start_b)]\n",
    "    w, b = start_w, start_b\n",
    "    \n",
    "    for i in range(num_steps):\n",
    "        # Calculate gradient at the current position\n",
    "        grad_w, grad_b = gradient(w, b)\n",
    "        \n",
    "        # Update parameters by taking a step in the opposite direction of the gradient\n",
    "        w = w - learning_rate * grad_w\n",
    "        b = b - learning_rate * grad_b\n",
    "        \n",
    "        path.append((w, b))\n",
    "        \n",
    "    return np.array(path)\n",
    "\n",
    "def visualize_gradient_descent(learning_rate=0.1, num_steps=20):\n",
    "    \"\"\"\n",
    "    Visualize the path of gradient descent on the contour plot.\n",
    "    \"\"\"\n",
    "    start_w, start_b = -1.5, 6.0\n",
    "    path = gradient_descent(start_w, start_b, learning_rate, num_steps)\n",
    "    \n",
    "    # Create the contour plot\n",
    "    w_grid = np.linspace(-2, 6, 100)\n",
    "    b_grid = np.linspace(-1, 7, 100)\n",
    "    W, B = np.meshgrid(w_grid, b_grid)\n",
    "    L = loss_function(W, B)\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.contour(W, B, L, levels=20, cmap='viridis', alpha=0.7)\n",
    "    \n",
    "    # Plot the path\n",
    "    plt.plot(path[:, 0], path[:, 1], 'r-o', markersize=5, label='Gradient Descent Path')\n",
    "    plt.plot(path[0, 0], path[0, 1], 'go', markersize=15, label='Start')\n",
    "    plt.plot(2, 3, 'y*', markersize=20, label='Minimum')\n",
    "    \n",
    "    plt.title(f'Gradient Descent with Learning Rate Œ∑ = {learning_rate}', fontsize=16, weight='bold')\n",
    "    plt.xlabel('Parameter w')\n",
    "    plt.ylabel('Parameter b')\n",
    "    plt.legend()\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "    \n",
    "    final_w, final_b = path[-1]\n",
    "    final_loss = loss_function(final_w, final_b)\n",
    "    print(f\"--- Results after {num_steps} steps ---\")\n",
    "    print(f\"Final parameters: (w, b) = ({final_w:.4f}, {final_b:.4f})\")\n",
    "    print(f\"Final loss: {final_loss:.4f}\")\n",
    "    print(f\"True minimum is at (2, 3) with loss 1.0\")\n",
    "\n",
    "# Interactive widget to explore the learning rate\n",
    "interact(\n",
    "    visualize_gradient_descent,\n",
    "    learning_rate=widgets.FloatSlider(value=0.1, min=0.01, max=0.49, step=0.02, description='Learning Rate (Œ∑):'),\n",
    "    num_steps=widgets.IntSlider(value=20, min=5, max=50, step=1, description='Num Steps:')\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e39df8",
   "metadata": {},
   "source": [
    "### The Importance of the Learning Rate (Œ∑)\n",
    "\n",
    "Use the interactive slider above to see how the learning rate affects the optimization process:\n",
    "\n",
    "- **Too Small (e.g., 0.01)**: The algorithm converges very slowly. It takes tiny steps and may need a huge number of iterations to reach the minimum.\n",
    "- **Just Right (e.g., 0.1 - 0.2)**: The algorithm converges smoothly and efficiently to the minimum.\n",
    "- **Too Large (e.g., > 0.45 for this function)**: The algorithm **overshoots** the minimum. The steps are so large that it jumps across the valley and ends up further away. This can lead to **divergence**, where the loss actually increases over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afbce5d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ü§Ø Chapter 3: The Challenge of Non-Convex Functions\n",
    "\n",
    "Our example used a simple, bowl-shaped **convex** function with one global minimum. Real-world loss surfaces, especially in deep learning, are **non-convex** and much more complex. They can have:\n",
    "\n",
    "- **Local Minima**: Points that are minimal within a local region, but not the overall lowest point.\n",
    "- **Saddle Points**: Points where the gradient is zero, but it's not a minimum (it's a minimum in one direction and a maximum in another).\n",
    "\n",
    "Gradient descent can get 'stuck' in a poor local minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3941e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_convex_loss(w, b):\n",
    "    \"\"\"\n",
    "    A more complex, non-convex loss function with multiple minima.\n",
    "    \"\"\"\n",
    "    return (w**2 + b - 11)**2 + (w + b**2 - 7)**2\n",
    "\n",
    "def non_convex_gradient(w, b):\n",
    "    \"\"\"\n",
    "    Gradient for the non-convex loss function (Himmelblau's function).\n",
    "    \"\"\"\n",
    "    grad_w = 2 * (w**2 + b - 11) * (2*w) + 2 * (w + b**2 - 7)\n",
    "    grad_b = 2 * (w**2 + b - 11) + 2 * (w + b**2 - 7) * (2*b)\n",
    "    return grad_w, grad_b\n",
    "\n",
    "def visualize_non_convex_descent(start_w, start_b):\n",
    "    \"\"\"\n",
    "    Visualize gradient descent on a non-convex surface from different starting points.\n",
    "    \"\"\"\n",
    "    # Grid for plotting\n",
    "    w_grid = np.linspace(-5, 5, 100)\n",
    "    b_grid = np.linspace(-5, 5, 100)\n",
    "    W, B = np.meshgrid(w_grid, b_grid)\n",
    "    L = non_convex_loss(W, B)\n",
    "    \n",
    "    # Run gradient descent\n",
    "    path = [(start_w, start_b)]\n",
    "    w, b = start_w, start_b\n",
    "    learning_rate = 0.01\n",
    "    num_steps = 100\n",
    "    \n",
    "    for _ in range(num_steps):\n",
    "        grad_w, grad_b = non_convex_gradient(w, b)\n",
    "        w -= learning_rate * grad_w\n",
    "        b -= learning_rate * grad_b\n",
    "        path.append((w, b))\n",
    "    path = np.array(path)\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.contour(W, B, L, levels=np.logspace(0, 5, 35), cmap='viridis')\n",
    "    plt.plot(path[:, 0], path[:, 1], 'r-o', markersize=4, label=f'Path from ({start_w}, {start_b})')\n",
    "    plt.plot(start_w, start_b, 'go', markersize=15, label='Start')\n",
    "    \n",
    "    # Mark the four minima of Himmelblau's function\n",
    "    minima = np.array([[3, 2], [-2.805, 3.131], [-3.779, -3.283], [3.584, -1.848]])\n",
    "    plt.plot(minima[:, 0], minima[:, 1], 'y*', markersize=20, label='Local Minima', linestyle='none')\n",
    "    \n",
    "    plt.title('Gradient Descent on a Non-Convex Surface', fontsize=16, weight='bold')\n",
    "    plt.xlabel('Parameter w')\n",
    "    plt.ylabel('Parameter b')\n",
    "    plt.legend()\n",
    "    plt.axis('equal')\n",
    "    plt.xlim(-5, 5)\n",
    "    plt.ylim(-5, 5)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Starting at ({start_w}, {start_b}), the algorithm converged near ({path[-1, 0]:.2f}, {path[-1, 1]:.2f}).\")\n",
    "\n",
    "# Interactive widget to choose starting point\n",
    "interact(\n",
    "    visualize_non_convex_descent,\n",
    "    start_w=widgets.FloatSlider(value=-4, min=-5, max=5, step=0.5, description='Start w:'),\n",
    "    start_b=widgets.FloatSlider(value=4, min=-5, max=5, step=0.5, description='Start b:')\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a249ce",
   "metadata": {},
   "source": [
    "Try different starting points with the sliders. You'll see that Gradient Descent is a **local** optimization algorithm. The minimum it finds depends entirely on where it starts. This is a major challenge in deep learning, and it's why more advanced optimizers were developed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b12dde2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üéØ Key Takeaways\n",
    "\n",
    "## üìâ The Core Idea\n",
    "- **Goal**: Find model parameters that minimize a loss function.\n",
    "- **Method**: Follow the path of steepest descent, which is the opposite direction of the gradient.\n",
    "- **Mechanism**: Iteratively update parameters using the rule: `new_param = old_param - learning_rate * gradient`.\n",
    "\n",
    "## üîë The Learning Rate (Œ∑)\n",
    "- **Crucial Hyperparameter**: Controls the step size of the algorithm.\n",
    "- **Trade-off**: Too small leads to slow convergence; too large leads to overshooting and divergence.\n",
    "- **Tuning**: Finding a good learning rate is a key part of training machine learning models.\n",
    "\n",
    "## ‚õ∞Ô∏è The Challenges\n",
    "- **Local Minima**: Gradient Descent can get stuck in suboptimal solutions on non-convex loss surfaces.\n",
    "- **Dependence on Starting Point**: The final solution depends on the initial parameter values.\n",
    "\n",
    "---\n",
    "\n",
    "# üöÄ What's Next?\n",
    "\n",
    "Vanilla Gradient Descent requires calculating the gradient over the *entire* dataset for every single step, which is computationally expensive for large datasets. In the next notebook, we'll explore **Stochastic Gradient Descent (SGD)** and its variants, which provide a much more efficient way to train models.\n",
    "\n",
    "- **Batch vs. Mini-Batch vs. Stochastic Gradient Descent**\n",
    "- **The benefits of noisy updates**\n",
    "- **Convergence properties and trade-offs**\n",
    "\n",
    "**Ready to make optimization more efficient? Let's dive into SGD! ‚ö°**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
