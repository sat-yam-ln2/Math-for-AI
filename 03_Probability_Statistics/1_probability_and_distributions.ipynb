{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82b8650a",
   "metadata": {},
   "source": [
    "# ðŸŽ² Probability & Distributions: The Foundation of Uncertainty in AI\n",
    "\n",
    "> *\"Probability theory is nothing but common sense reduced to calculation.\"* - Pierre-Simon Laplace\n",
    "\n",
    "Welcome to the world of **Probability and Statistics**! This is the mathematical framework that allows AI to reason about uncertainty, make predictions from noisy data, and learn patterns in a world that is not deterministic.\n",
    "\n",
    "## ðŸŽ¯ What You'll Master\n",
    "\n",
    "- **Fundamentals of Probability**: Sample spaces, events, and axioms.\n",
    "- **Random Variables**: Discrete and continuous variables with their PMFs, PDFs, and CDFs.\n",
    "- **Key Probability Distributions**: Visualizing and understanding Uniform, Binomial, and the all-important Normal distribution.\n",
    "- **AI Connections**: How probability underpins machine learning models and algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597642ce",
   "metadata": {},
   "source": [
    "## ðŸ“š Import Essential Libraries\n",
    "\n",
    "Let's load the libraries we'll need for our statistical exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f4075a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries for data manipulation and mathematics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Interactive widgets\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"colorblind\")\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 7)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"ðŸŽ² Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df77b843",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸŽ² Chapter 1: The Basics of Probability\n",
    "\n",
    "**Probability** is a measure of the likelihood that an event will occur. It's a number between 0 and 1, where:\n",
    "- **0** indicates impossibility.\n",
    "- **1** indicates certainty.\n",
    "\n",
    "### Key Concepts\n",
    "- **Experiment**: An action or process with an uncertain outcome (e.g., rolling a die).\n",
    "- **Sample Space (S)**: The set of all possible outcomes of an experiment (e.g., {1, 2, 3, 4, 5, 6}).\n",
    "- **Event (E)**: A subset of the sample space (e.g., rolling an even number: {2, 4, 6}).\n",
    "\n",
    "The probability of an event E is:\n",
    "$$ P(E) = \\frac{\\text{Number of favorable outcomes}}{\\text{Total number of outcomes in the sample space}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7836fa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_dice_roll():\n",
    "    \"\"\"\n",
    "    Visualize the sample space and an event for a single die roll.\n",
    "    \"\"\"\n",
    "    sample_space = list(range(1, 7))\n",
    "    event_even = [x for x in sample_space if x % 2 == 0]\n",
    "    \n",
    "    prob_even = len(event_even) / len(sample_space)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    \n",
    "    # Plot sample space\n",
    "    ax.bar(sample_space, [1]*len(sample_space), color='lightblue', label='Sample Space (S)')\n",
    "    \n",
    "    # Highlight the event\n",
    "    ax.bar(event_even, [1]*len(event_even), color='salmon', label='Event (E): Roll is Even')\n",
    "    \n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks(sample_space)\n",
    "    ax.set_xlabel('Die Roll Outcome', fontsize=12)\n",
    "    ax.set_title('Visualizing a Simple Probability Experiment', fontsize=14, weight='bold')\n",
    "    ax.legend()\n",
    "    \n",
    "    # Add text annotation\n",
    "    ax.text(3.5, 0.5, f'P(E) = {len(event_even)} / {len(sample_space)} = {prob_even:.2f}',\n",
    "            fontsize=14, ha='center', va='center', \n",
    "            bbox=dict(boxstyle=\"round\", facecolor='wheat', alpha=0.8))\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Sample Space (S): {sample_space}\")\n",
    "    print(f\"Event (E) - Rolling an even number: {event_even}\")\n",
    "    print(f\"Probability of E: {prob_even:.2f}\")\n",
    "\n",
    "visualize_dice_roll()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6149889b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸŽ° Chapter 2: Random Variables & Probability Distributions\n",
    "\n",
    "A **Random Variable** is a variable whose value is a numerical outcome of a random phenomenon.\n",
    "\n",
    "- **Discrete Random Variable**: Has a countable number of possible values (e.g., number of heads in 3 coin flips).\n",
    "- **Continuous Random Variable**: Can take any value in a given range (e.g., height of a person).\n",
    "\n",
    "A **Probability Distribution** describes how the probabilities are distributed over the values of the random variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c43aa7",
   "metadata": {},
   "source": [
    "### 1. Binomial Distribution (Discrete)\n",
    "\n",
    "Models the number of successes in a fixed number of independent trials.\n",
    "- **Parameters**: `n` (number of trials), `p` (probability of success in one trial).\n",
    "- **Use Case**: A/B testing conversion rates, number of defective items in a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36127c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_binomial_distribution(n=10, p=0.5):\n",
    "    \"\"\"\n",
    "    Plot the Probability Mass Function (PMF) and Cumulative Distribution Function (CDF)\n",
    "    for a Binomial distribution.\n",
    "    \"\"\"\n",
    "    # x values (number of successes)\n",
    "    k = np.arange(0, n + 1)\n",
    "    \n",
    "    # PMF and CDF\n",
    "    pmf = stats.binom.pmf(k, n, p)\n",
    "    cdf = stats.binom.cdf(k, n, p)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Plot PMF\n",
    "    ax1.bar(k, pmf, color='skyblue', edgecolor='black')\n",
    "    ax1.set_title(f'Binomial PMF (n={n}, p={p})', fontsize=14, weight='bold')\n",
    "    ax1.set_xlabel('Number of Successes (k)')\n",
    "    ax1.set_ylabel('Probability')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot CDF\n",
    "    ax2.step(k, cdf, where='post', color='salmon', linewidth=2)\n",
    "    ax2.set_title(f'Binomial CDF (n={n}, p={p})', fontsize=14, weight='bold')\n",
    "    ax2.set_xlabel('Number of Successes (k)')\n",
    "    ax2.set_ylabel('Cumulative Probability')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_ylim(0, 1.1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    mean, var = stats.binom.stats(n, p, moments='mv')\n",
    "    print(f\"Binomial Distribution (n={n}, p={p}):\")\n",
    "    print(f\"  - Expected Value (Mean): {mean:.2f}\")\n",
    "    print(f\"  - Variance: {var:.2f}\")\n",
    "\n",
    "# Interactive widget for Binomial distribution\n",
    "interact(\n",
    "    plot_binomial_distribution,\n",
    "    n=widgets.IntSlider(value=20, min=1, max=100, step=1, description='n (trials):'),\n",
    "    p=widgets.FloatSlider(value=0.5, min=0.0, max=1.0, step=0.01, description='p (prob):')\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4522cf1f",
   "metadata": {},
   "source": [
    "### 2. Normal (Gaussian) Distribution (Continuous)\n",
    "\n",
    "The most famous distribution, characterized by its bell shape. It's central to statistics due to the **Central Limit Theorem**.\n",
    "- **Parameters**: `Î¼` (mean), `Ïƒ` (standard deviation).\n",
    "- **Use Case**: Modeling natural phenomena (heights, weights), errors in measurements, initializing neural network weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d8a9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_normal_distribution(mu=0, sigma=1):\n",
    "    \"\"\"\n",
    "    Plot the Probability Density Function (PDF) and CDF for a Normal distribution.\n",
    "    \"\"\"\n",
    "    # x values\n",
    "    x = np.linspace(mu - 4*sigma, mu + 4*sigma, 1000)\n",
    "    \n",
    "    # PDF and CDF\n",
    "    pdf = stats.norm.pdf(x, loc=mu, scale=sigma)\n",
    "    cdf = stats.norm.cdf(x, loc=mu, scale=sigma)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Plot PDF\n",
    "    ax1.plot(x, pdf, color='limegreen', linewidth=2)\n",
    "    ax1.fill_between(x, pdf, color='limegreen', alpha=0.2)\n",
    "    ax1.set_title(f'Normal PDF (Î¼={mu}, Ïƒ={sigma})', fontsize=14, weight='bold')\n",
    "    ax1.set_xlabel('Value (x)')\n",
    "    ax1.set_ylabel('Probability Density')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add standard deviation lines\n",
    "    for i in range(1, 4):\n",
    "        ax1.axvline(mu + i*sigma, color='red', linestyle='--', alpha=0.5, label=f'{i}Ïƒ' if i==1 else None)\n",
    "        ax1.axvline(mu - i*sigma, color='red', linestyle='--', alpha=0.5)\n",
    "    ax1.legend()\n",
    "\n",
    "    # Plot CDF\n",
    "    ax2.plot(x, cdf, color='darkorange', linewidth=2)\n",
    "    ax2.set_title(f'Normal CDF (Î¼={mu}, Ïƒ={sigma})', fontsize=14, weight='bold')\n",
    "    ax2.set_xlabel('Value (x)')\n",
    "    ax2.set_ylabel('Cumulative Probability')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Empirical Rule (68-95-99.7)\n",
    "    p_1_sigma = stats.norm.cdf(mu + sigma, mu, sigma) - stats.norm.cdf(mu - sigma, mu, sigma)\n",
    "    p_2_sigma = stats.norm.cdf(mu + 2*sigma, mu, sigma) - stats.norm.cdf(mu - 2*sigma, mu, sigma)\n",
    "    p_3_sigma = stats.norm.cdf(mu + 3*sigma, mu, sigma) - stats.norm.cdf(mu - 3*sigma, mu, sigma)\n",
    "    \n",
    "    print(f\"Normal Distribution (Î¼={mu}, Ïƒ={sigma}):\")\n",
    "    print(f\"  - P(Î¼-Ïƒ < X < Î¼+Ïƒ) â‰ˆ {p_1_sigma:.3f} (68% rule)\")\n",
    "    print(f\"  - P(Î¼-2Ïƒ < X < Î¼+2Ïƒ) â‰ˆ {p_2_sigma:.3f} (95% rule)\")\n",
    "    print(f\"  - P(Î¼-3Ïƒ < X < Î¼+3Ïƒ) â‰ˆ {p_3_sigma:.3f} (99.7% rule)\")\n",
    "\n",
    "# Interactive widget for Normal distribution\n",
    "interact(\n",
    "    plot_normal_distribution,\n",
    "    mu=widgets.FloatSlider(value=0, min=-5, max=5, step=0.1, description='Î¼ (mean):'),\n",
    "    sigma=widgets.FloatSlider(value=1, min=0.1, max=5, step=0.1, description='Ïƒ (std dev):')\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48a12d9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸ§  Chapter 3: The Central Limit Theorem (CLT)\n",
    "\n",
    "The **Central Limit Theorem** is a cornerstone of statistics. It states that the distribution of the **sum (or average) of a large number of independent, identically distributed random variables** will be approximately normal, regardless of the underlying distribution.\n",
    "\n",
    "**Why is this so important for AI?**\n",
    "- It justifies the use of normal distributions to model aggregate effects.\n",
    "- It explains why many real-world phenomena appear to be normally distributed.\n",
    "- It's the foundation for many statistical tests and confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17770a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_central_limit_theorem(n_samples=1000, sample_size=30):\n",
    "    \"\"\"\n",
    "    Demonstrate the Central Limit Theorem using a Uniform distribution.\n",
    "    \"\"\"\n",
    "    # We'll sample from a Uniform distribution, which is decidedly not normal.\n",
    "    underlying_dist = stats.uniform(loc=0, scale=10)\n",
    "    \n",
    "    # Generate many sample means\n",
    "    sample_means = []\n",
    "    for _ in range(n_samples):\n",
    "        sample = underlying_dist.rvs(size=sample_size)\n",
    "        sample_means.append(np.mean(sample))\n",
    "        \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Plot the underlying distribution\n",
    "    x = np.linspace(-2, 12, 200)\n",
    "    ax1.plot(x, underlying_dist.pdf(x), 'b-', lw=2, label='Uniform PDF')\n",
    "    ax1.set_title('Underlying Distribution (Uniform)', fontsize=14, weight='bold')\n",
    "    ax1.set_xlabel('Value')\n",
    "    ax1.set_ylabel('Density')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot the distribution of sample means\n",
    "    sns.histplot(sample_means, kde=True, ax=ax2, color='purple', stat='density')\n",
    "    \n",
    "    # Overlay the theoretical normal distribution\n",
    "    mu = underlying_dist.mean()\n",
    "    sigma = underlying_dist.std() / np.sqrt(sample_size)\n",
    "    x_norm = np.linspace(min(sample_means), max(sample_means), 100)\n",
    "    ax2.plot(x_norm, stats.norm.pdf(x_norm, mu, sigma), 'r--', lw=2, label='Theoretical Normal PDF')\n",
    "    \n",
    "    ax2.set_title(f'Distribution of Sample Means (n={sample_size})', fontsize=14, weight='bold')\n",
    "    ax2.set_xlabel('Sample Mean')\n",
    "    ax2.set_ylabel('Density')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('Central Limit Theorem in Action', fontsize=16, weight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Demonstrating CLT with {n_samples} samples of size {sample_size}:\")\n",
    "    print(f\"  - Underlying Mean: {underlying_dist.mean():.2f}\")\n",
    "    print(f\"  - Mean of Sample Means: {np.mean(sample_means):.2f}\")\n",
    "    print(f\"  - Underlying Std Dev: {underlying_dist.std():.2f}\")\n",
    "    print(f\"  - Std Dev of Sample Means (Theoretical): {sigma:.2f}\")\n",
    "    print(f\"  - Std Dev of Sample Means (Observed): {np.std(sample_means):.2f}\")\n",
    "\n",
    "# Interactive widget for CLT\n",
    "interact(\n",
    "    visualize_central_limit_theorem,\n",
    "    n_samples=widgets.IntSlider(value=1000, min=100, max=10000, step=100, description='Num Samples:'),\n",
    "    sample_size=widgets.IntSlider(value=30, min=1, max=500, step=1, description='Sample Size:')\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87fd538",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸŽ¯ Key Takeaways\n",
    "\n",
    "## ðŸŽ² Probability Basics\n",
    "- **Language of Uncertainty**: Provides a formal way to reason about randomness.\n",
    "- **Foundation**: Built on sample spaces, events, and axioms.\n",
    "\n",
    "## ðŸŽ° Probability Distributions\n",
    "- **Models for Data**: Describe the likelihood of different outcomes for a random variable.\n",
    "- **Discrete vs. Continuous**: Binomial for counts, Normal for measurements.\n",
    "- **Key Functions**: PMF/PDF for likelihood, CDF for cumulative probability.\n",
    "\n",
    "## ðŸ”” Central Limit Theorem\n",
    "- **The Star of Statistics**: The distribution of sample means tends to be normal, even if the source isn't.\n",
    "- **Practical Implications**: Justifies using normal-based models and tests in many real-world scenarios.\n",
    "\n",
    "## ðŸ§  AI Connections\n",
    "- **Generative Models**: Learn and sample from complex data distributions (e.g., GANs, VAEs).\n",
    "- **Probabilistic Models**: Explicitly model uncertainty (e.g., Bayesian networks, Gaussian Mixture Models).\n",
    "- **Optimization**: Stochastic Gradient Descent relies on random sampling of data.\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸš€ What's Next?\n",
    "\n",
    "In the next notebook, we'll move from theory to practice with **Descriptive Statistics**. We'll learn how to summarize, visualize, and interpret datasets using key statistical measures.\n",
    "\n",
    "- **Measures of Central Tendency**: Mean, Median, Mode\n",
    "- **Measures of Dispersion**: Variance, Standard Deviation, Range\n",
    "- **Correlation and Covariance**: Understanding relationships between variables\n",
    "\n",
    "**Ready to describe your data? Let's go! ðŸ“Š**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
