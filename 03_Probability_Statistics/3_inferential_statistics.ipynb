{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3cfb8b9",
   "metadata": {},
   "source": [
    "# üîé Inferential Statistics: Making Conclusions from Data\n",
    "\n",
    "> *\"Essentially, all models are wrong, but some are useful.\"* - George Box\n",
    "\n",
    "Welcome to **Inferential Statistics**! While descriptive statistics summarizes a given dataset, inferential statistics uses that data to make predictions, decisions, and generalizations about a larger population. This is where we move from *what the data is* to *what the data means*.\n",
    "\n",
    "## üéØ What You'll Master\n",
    "\n",
    "- **Hypothesis Testing**: The formal framework for making decisions from data (e.g., is this new drug effective?).\n",
    "- **p-values**: Understanding and correctly interpreting this often-misunderstood metric.\n",
    "- **Confidence Intervals**: Estimating a population parameter with a range of plausible values.\n",
    "- **t-tests**: A practical tool for comparing the means of two groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf92a573",
   "metadata": {},
   "source": [
    "## üìö Import Essential Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec92d274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"muted\")\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 7)\n",
    "plt.rcParams['font.size'] = 13\n",
    "\n",
    "print(\"üîé Libraries loaded for inferential statistics!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dc2e0b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üî¨ Chapter 1: Hypothesis Testing\n",
    "\n",
    "**Hypothesis testing** is a formal procedure for checking if a hypothesis is supported by the data. It's like a mathematical version of the legal principle \"innocent until proven guilty.\"\n",
    "\n",
    "### The Two Hypotheses\n",
    "1. **Null Hypothesis (H‚ÇÄ)**: The default assumption, a statement of no effect or no difference. (The defendant is innocent).\n",
    "2. **Alternative Hypothesis (H‚ÇÅ or Ha)**: The claim we want to test. It's what we'll accept if we have enough evidence to reject H‚ÇÄ. (The defendant is guilty).\n",
    "\n",
    "### The Process\n",
    "1. State H‚ÇÄ and H‚ÇÅ.\n",
    "2. Choose a significance level (Œ±), usually 0.05. This is the probability of rejecting H‚ÇÄ when it's actually true (a \"false positive\").\n",
    "3. Collect data and calculate a test statistic.\n",
    "4. Calculate the **p-value**: The probability of observing data as extreme as, or more extreme than, what you collected, *assuming the null hypothesis is true*.\n",
    "5. Make a decision:\n",
    "   - If **p-value < Œ±**, we **reject the null hypothesis**. We have statistically significant evidence for the alternative.\n",
    "   - If **p-value ‚â• Œ±**, we **fail to reject the null hypothesis**. We do not have enough evidence to support the alternative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33c7d2d",
   "metadata": {},
   "source": [
    "### Example: A/B Testing a Website\n",
    "\n",
    "Let's simulate an A/B test. A company wants to know if changing the color of a \"Buy Now\" button from blue (Group A) to green (Group B) increases the click-through rate (CTR).\n",
    "\n",
    "- **H‚ÇÄ**: The CTR of the green button is the same as the blue button.\n",
    "- **H‚ÇÅ**: The CTR of the green button is different from the blue button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070c8992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_ab_test():\n",
    "    \"\"\"\n",
    "    Simulate and analyze a simple A/B test for website button clicks.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Parameters\n",
    "    n_A = 1000  # Visitors for blue button\n",
    "    n_B = 1000  # Visitors for green button\n",
    "    ctr_A_true = 0.10  # True CTR for blue\n",
    "    ctr_B_true = 0.12  # True CTR for green (a 2% absolute improvement)\n",
    "    \n",
    "    # Simulate clicks (as a binomial process)\n",
    "    clicks_A = np.random.binomial(n_A, ctr_A_true)\n",
    "    clicks_B = np.random.binomial(n_B, ctr_B_true)\n",
    "    \n",
    "    # Observed CTRs\n",
    "    ctr_A_obs = clicks_A / n_A\n",
    "    ctr_B_obs = clicks_B / n_B\n",
    "    \n",
    "    # Perform the hypothesis test (chi-squared test for proportions)\n",
    "    contingency_table = np.array([\n",
    "        [clicks_A, n_A - clicks_A], # Clicks, No-clicks for A\n",
    "        [clicks_B, n_B - clicks_B]  # Clicks, No-clicks for B\n",
    "    ])\n",
    "    \n",
    "    chi2, p_value, _, _ = stats.chi2_contingency(contingency_table, correction=False)\n",
    "    \n",
    "    # Visualization\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    sns.barplot(x=['Blue Button (A)', 'Green Button (B)'], y=[ctr_A_obs, ctr_B_obs], ax=ax, palette=['cornflowerblue', 'mediumseagreen'])\n",
    "    ax.set_ylabel('Observed Click-Through Rate (CTR)')\n",
    "    ax.set_title('A/B Test Results', fontsize=16, weight='bold')\n",
    "    ax.set_ylim(0, max(ctr_A_obs, ctr_B_obs) * 1.2)\n",
    "    for i, v in enumerate([ctr_A_obs, ctr_B_obs]):\n",
    "        ax.text(i, v + 0.005, f'{v:.3f}', ha='center', fontsize=12)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Print results\n",
    "    print(\"--- A/B Test Analysis ---\")\n",
    "    print(f\"Group A (Blue): {clicks_A} clicks out of {n_A} visitors -> CTR = {ctr_A_obs:.3f}\")\n",
    "    print(f\"Group B (Green): {clicks_B} clicks out of {n_B} visitors -> CTR = {ctr_B_obs:.3f}\")\n",
    "    print(f\"\\nChi-Squared Test Statistic: {chi2:.4f}\")\n",
    "    print(f\"p-value: {p_value:.4f}\")\n",
    "    \n",
    "    # Conclusion\n",
    "    alpha = 0.05\n",
    "    print(f\"\\nSignificance Level (Œ±): {alpha}\")\n",
    "    if p_value < alpha:\n",
    "        print(f\"‚úÖ Decision: Reject the null hypothesis (p-value < {alpha}).\")\n",
    "        print(\"   Conclusion: There is a statistically significant difference in CTR between the blue and green buttons.\")\n",
    "    else:\n",
    "        print(f\"‚ùå Decision: Fail to reject the null hypothesis (p-value ‚â• {alpha}).\")\n",
    "        print(\"   Conclusion: We do not have enough evidence to say there's a difference in CTR.\")\n",
    "\n",
    "simulate_ab_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04190a5c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üìä Chapter 2: p-values and Confidence Intervals\n",
    "\n",
    "### Understanding the p-value\n",
    "\n",
    "The **p-value** is one of the most misinterpreted concepts in statistics. \n",
    "\n",
    "**What it IS**: The probability of getting your observed result (or something more extreme) if the null hypothesis were true.\n",
    "**What it is NOT**:\n",
    "- It is NOT the probability that the null hypothesis is true.\n",
    "- It is NOT the probability that the alternative hypothesis is false.\n",
    "- A small p-value does NOT prove your alternative hypothesis is true; it only provides evidence against the null.\n",
    "\n",
    "Let's visualize what a p-value represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fc407a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_p_value():\n",
    "    \"\"\"\n",
    "    Visualize the concept of a p-value under a null distribution.\n",
    "    \"\"\"\n",
    "    # Assume H0 is true: mean = 0. We are using a standard normal distribution.\n",
    "    mu_h0 = 0\n",
    "    sigma_h0 = 1\n",
    "    \n",
    "    # Let's say we observed a test statistic of 1.96 (e.g., from a z-test)\n",
    "    observed_statistic = 1.96\n",
    "    \n",
    "    # Calculate the p-value for a two-tailed test\n",
    "    p_value = 2 * (1 - stats.norm.cdf(observed_statistic, loc=mu_h0, scale=sigma_h0))\n",
    "    \n",
    "    x = np.linspace(-4, 4, 1000)\n",
    "    y = stats.norm.pdf(x, loc=mu_h0, scale=sigma_h0)\n",
    "    \n",
    "    plt.figure(figsize=(12, 7))\n",
    "    plt.plot(x, y, 'b-', label='Null Hypothesis Distribution (H‚ÇÄ)')\n",
    "    \n",
    "    # Shade the area for the p-value\n",
    "    x_fill = np.linspace(observed_statistic, 4, 100)\n",
    "    plt.fill_between(x_fill, stats.norm.pdf(x_fill, mu_h0, sigma_h0), color='red', alpha=0.5, label='p-value area (one tail)')\n",
    "    x_fill_neg = np.linspace(-4, -observed_statistic, 100)\n",
    "    plt.fill_between(x_fill_neg, stats.norm.pdf(x_fill_neg, mu_h0, sigma_h0), color='red', alpha=0.5, label='p-value area (other tail)')\n",
    "    \n",
    "    plt.axvline(observed_statistic, color='red', linestyle='--', lw=2, label=f'Observed Statistic = {observed_statistic}')\n",
    "    plt.axvline(-observed_statistic, color='red', linestyle='--', lw=2)\n",
    "    \n",
    "    plt.title('Visualizing a p-value for a Two-Tailed Test', fontsize=16, weight='bold')\n",
    "    plt.xlabel('Test Statistic Value')\n",
    "    plt.ylabel('Probability Density')\n",
    "    plt.legend()\n",
    "    plt.text(0, 0.1, f'p-value = {p_value:.3f}', ha='center', fontsize=14, bbox=dict(facecolor='white', alpha=0.8))\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"üí° The p-value is the total shaded red area.\")\n",
    "    print(\"It represents the probability of seeing a result as extreme as (or more extreme than) our observed statistic, assuming H‚ÇÄ is true.\")\n",
    "\n",
    "visualize_p_value()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34067c97",
   "metadata": {},
   "source": [
    "### Confidence Intervals\n",
    "\n",
    "A **Confidence Interval (CI)** provides a range of plausible values for an unknown population parameter (like the mean or proportion). It's an alternative to a point estimate.\n",
    "\n",
    "A **95% confidence interval** means that if we were to repeat our sampling process many times, 95% of the calculated confidence intervals would contain the true population parameter.\n",
    "\n",
    "**Formula for a mean**:  `CI = sample_mean ¬± margin_of_error`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602d4f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_confidence_intervals():\n",
    "    \"\"\"\n",
    "    Demonstrate the meaning of a 95% confidence interval through simulation.\n",
    "    \"\"\"\n",
    "    np.random.seed(101)\n",
    "    \n",
    "    # Population parameters (unknown in real life)\n",
    "    true_mean = 50\n",
    "    true_std = 10\n",
    "    \n",
    "    n_simulations = 100\n",
    "    sample_size = 30\n",
    "    confidence_level = 0.95\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    n_captures = 0\n",
    "    for i in range(n_simulations):\n",
    "        # Take a sample from the population\n",
    "        sample = np.random.normal(loc=true_mean, scale=true_std, size=sample_size)\n",
    "        sample_mean = np.mean(sample)\n",
    "        \n",
    "        # Calculate the confidence interval\n",
    "        # Using stats.t.interval for a more robust calculation when std is estimated\n",
    "        ci_low, ci_high = stats.t.interval(confidence_level, df=sample_size-1, \n",
    "                                           loc=sample_mean, \n",
    "                                           scale=stats.sem(sample))\n",
    "        \n",
    "        # Check if the interval captures the true mean\n",
    "        captures_mean = ci_low <= true_mean <= ci_high\n",
    "        if captures_mean:\n",
    "            n_captures += 1\n",
    "        \n",
    "        color = 'blue' if captures_mean else 'red'\n",
    "        plt.plot([ci_low, ci_high], [i, i], color=color, linewidth=2)\n",
    "        plt.plot(sample_mean, i, 'o', color='black', markersize=3)\n",
    "\n",
    "    plt.axvline(true_mean, color='green', linestyle='--', lw=2, label=f'True Population Mean = {true_mean}')\n",
    "    plt.title(f'{n_simulations} Simulated 95% Confidence Intervals', fontsize=16, weight='bold')\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Simulation Number')\n",
    "    plt.yticks([])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    capture_rate = n_captures / n_simulations\n",
    "    print(f\"--- Confidence Interval Simulation ---\")\n",
    "    print(f\"Number of simulations: {n_simulations}\")\n",
    "    print(f\"Number of intervals that captured the true mean: {n_captures}\")\n",
    "    print(f\"Observed Capture Rate: {capture_rate:.2f} (Expected: {confidence_level:.2f})\")\n",
    "    print(\"\\nüí° Each blue line is a 95% CI from one sample that successfully 'captured' the true mean.\")\n",
    "    print(\"   Red lines are the ~5% of CIs that 'missed' the true mean by chance.\")\n",
    "\n",
    "visualize_confidence_intervals()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf42c82f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ‚öîÔ∏è Chapter 3: The t-test\n",
    "\n",
    "A **t-test** is a common type of hypothesis test used to determine if there is a significant difference between the means of two groups.\n",
    "\n",
    "### Example: Drug Efficacy\n",
    "Let's test if a new drug reduces blood pressure compared to a placebo.\n",
    "\n",
    "- **Group A**: Placebo\n",
    "- **Group B**: New Drug\n",
    "- **Measurement**: Change in blood pressure after 1 month.\n",
    "\n",
    "- **H‚ÇÄ**: The mean change in blood pressure is the same for the drug and placebo groups.\n",
    "- **H‚ÇÅ**: The mean change in blood pressure is different for the two groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42701f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_t_test():\n",
    "    \"\"\"\n",
    "    Simulate data for a drug trial and perform an independent t-test.\n",
    "    \"\"\"\n",
    "    np.random.seed(7)\n",
    "    \n",
    "    # Simulate data\n",
    "    # Placebo group: mean change of -2 (small placebo effect), std of 5\n",
    "    placebo_group = np.random.normal(loc=-2, scale=5, size=50)\n",
    "    # Drug group: mean change of -8 (stronger effect), std of 5\n",
    "    drug_group = np.random.normal(loc=-8, scale=5, size=50)\n",
    "    \n",
    "    # Perform the independent t-test\n",
    "    t_statistic, p_value = stats.ttest_ind(placebo_group, drug_group)\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    sns.kdeplot(placebo_group, fill=True, label='Placebo Group')\n",
    "    sns.kdeplot(drug_group, fill=True, label='Drug Group')\n",
    "    plt.axvline(np.mean(placebo_group), color=sns.color_palette()[0], linestyle='--', lw=2)\n",
    "    plt.axvline(np.mean(drug_group), color=sns.color_palette()[1], linestyle='--', lw=2)\n",
    "    plt.title('Distribution of Blood Pressure Change', fontsize=16, weight='bold')\n",
    "    plt.xlabel('Change in Blood Pressure (mmHg)')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print results\n",
    "    print(\"--- Independent t-test Results ---\")\n",
    "    print(f\"Placebo Group Mean: {np.mean(placebo_group):.2f}\")\n",
    "    print(f\"Drug Group Mean: {np.mean(drug_group):.2f}\")\n",
    "    print(f\"\\nt-statistic: {t_statistic:.4f}\")\n",
    "    print(f\"p-value: {p_value:.4f}\")\n",
    "    \n",
    "    # Conclusion\n",
    "    alpha = 0.05\n",
    "    print(f\"\\nSignificance Level (Œ±): {alpha}\")\n",
    "    if p_value < alpha:\n",
    "        print(f\"‚úÖ Decision: Reject the null hypothesis (p-value < {alpha}).\")\n",
    "        print(\"   Conclusion: There is a statistically significant difference between the drug and placebo groups.\")\n",
    "    else:\n",
    "        print(f\"‚ùå Decision: Fail to reject the null hypothesis (p-value ‚â• {alpha}).\")\n",
    "        print(\"   Conclusion: We do not have enough evidence to say the drug had a different effect than the placebo.\")\n",
    "\n",
    "perform_t_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828e8946",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üéØ Key Takeaways\n",
    "\n",
    "## üî¨ The Scientific Method for Data\n",
    "- **Hypothesis Testing**: Provides a structured way to ask and answer questions using data, forming the backbone of data-driven decision making.\n",
    "- **Null Hypothesis (H‚ÇÄ)**: The default assumption of 'no effect'. We need strong evidence to overturn it.\n",
    "\n",
    "## üìä Interpreting the Results\n",
    "- **p-value**: A measure of surprise. A small p-value means our data is surprising *if the null hypothesis is true*, leading us to question the null.\n",
    "- **Confidence Interval**: A range of plausible values for a population parameter, giving us a sense of estimation uncertainty.\n",
    "- **Statistical Significance**: When p < Œ±, the result is called 'statistically significant'. This doesn't necessarily mean it's practically important, just that it's unlikely to be due to random chance alone.\n",
    "\n",
    "## üß† AI Connections\n",
    "- **A/B Testing**: The core of evaluating changes in products, from websites to recommendation algorithms.\n",
    "- **Model Comparison**: Hypothesis tests can be used to determine if one machine learning model is significantly better than another.\n",
    "- **Feature Selection**: Inferential tests can help decide if a feature has a statistically significant relationship with the target variable.\n",
    "- **Causal Inference**: While this notebook focused on basic tests, the field of causal inference builds on these ideas to try and determine cause-and-effect relationships from data, a major frontier in AI.\n",
    "\n",
    "---\n",
    "\n",
    "# üöÄ What's Next?\n",
    "\n",
    "This concludes our core journey through Probability and Statistics! The next section of this course will dive into **Optimization**, the engine that drives machine learning, allowing models to 'learn' from data by minimizing a loss function. We'll see how concepts like gradients (from Calculus) and random sampling (from Statistics) come together.\n",
    "\n",
    "**Ready to find the minimum? Let's move on to Optimization! üìâ**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
